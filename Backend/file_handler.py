# --------------------------------------------------
# File: file_handler.py (FINAL FIXED VERSION)
# Description: í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° í…ìŠ¤íŠ¸ ì²­í¬ ìƒì„± ê¸°ëŠ¥
# --------------------------------------------------

import fitz
import re
import csv
import os
import json
from typing import List, Dict

BASE_DIR = os.path.join(os.path.expanduser("~"), "RAG_Chatbot")
CONFIG_PATH = os.path.join(BASE_DIR, "chunk_config.json")

DEFAULT_CONFIG = {
    "default": {"strategy": "regular", "chunk_size": 800, "overlap": 80},
    "pdf": {},
    "csv": {}
}

def load_config():
    if not os.path.exists(CONFIG_PATH):
        return DEFAULT_CONFIG
    try:
        with open(CONFIG_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return DEFAULT_CONFIG

#  ===== PDF Reader â€” ì¤„ë°”ê¿ˆ ìœ ì§€ + í˜ì´ì§€ í…ìŠ¤íŠ¸ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜ =====
def pdf_to_text_with_page(pdf_path: str, file_name: str) -> List[Dict]:
    doc = fitz.open(pdf_path)
    pages = []
    for page in doc:
        # ğŸ”¥ ì¤„ë°”ê¿ˆì€ ìœ ì§€í•´ì•¼ category / law íŒŒì„œ ì‚¬ìš© ê°€ëŠ¥
        text = page.get_text("text")
        text = text.replace("\r", "").strip()

        pages.append({
            "page_no": page.number + 1,
            "text": text,
            "file_name": file_name
        })
    doc.close()
    return pages



#  ===== CSV Reader =====
def csv_to_text(file_path: str) -> str:
    rows = []
    with open(file_path, newline="", encoding="utf-8") as csvfile:
        reader = csv.reader(csvfile)
        for row in reader:
            rows.append(",".join(row))
    return "\n".join(rows)

#  ===== CATEGORY PARSER â€” category.pdf ì „ìš© íŒŒì„œ =====
def parse_category_structure(raw_text: str) -> List[Dict]:
    import re

    lines = [l.strip() for l in raw_text.split("\n") if l.strip()]
    chunks = []

    # ë‘ ì¤„ íŒ¨í„´ë§Œ ì‚¬ìš©
    title_mark_re = re.compile(r"^\d+\.$")        # "1."
    subtitle_mark_re = re.compile(r"^[A-Z]\.$")   # "A."
    item_mark_re = re.compile(r"^(i|ii|iii|iv|v|vi|vii|viii|ix|x)\.$", re.IGNORECASE)
    url_re = re.compile(r"\((https?://[^\)]+)\)")

    title = None
    subtitle = None

    i = 0
    while i < len(lines):
        line = lines[i]

        # 1) Title = "1." + ë‹¤ìŒ ì¤„ í…ìŠ¤íŠ¸
        if title_mark_re.match(line):
            if i + 1 < len(lines):
                title = lines[i + 1].strip()
                subtitle = None
            i += 2
            continue

        # 2) Subtitle = "A." + ë‹¤ìŒ ì¤„ í…ìŠ¤íŠ¸
        if subtitle_mark_re.match(line):
            if i + 1 < len(lines):
                subtitle = lines[i + 1].strip()
            i += 2
            continue

        # 3) Item = "i." + ë‹¤ìŒ ì¤„ í…ìŠ¤íŠ¸ + (URL)
        if item_mark_re.match(line):
            item_text = None
            item_url = ""

            # ë‹¤ìŒ ì¤„ = í…ìŠ¤íŠ¸
            if i + 1 < len(lines):
                item_text = lines[i + 1].strip()
                i += 2
            else:
                i += 1
                continue

            # ê·¸ ë‹¤ìŒ ì¤„ = URLì¸ì§€ ê²€ì‚¬
            if i < len(lines):
                m = url_re.search(lines[i])
                if m:
                    item_url = m.group(1)
                    i += 1

            # ì €ì¥
            if item_text:
                chunks.append({
                    "strategy": "category",
                    "title": title,
                    "subtitle": subtitle,
                    "text": item_text,
                    "url": item_url
                })

            continue

        i += 1

    return chunks

# ===== LAW PARSER â€” ì „í†µì‹œì¥ë²• / ì‹œí–‰ë ¹ / ì‹œí–‰ê·œì¹™ ì „ìš© =====
def parse_law_pdf_text(text: str) -> List[Dict]:
    """
    ì „í†µì‹œì¥ë²• / ì‹œí–‰ë ¹ / ì‹œí–‰ê·œì¹™ ë“± ë²•ë ¹ PDF íŒŒì‹± ì „ìš© í•¨ìˆ˜
    - í•œ ì¤„ì— ì¡°ë¬¸ì´ ì—¬ëŸ¬ ê°œ ë¶™ì–´ ìˆì–´ë„ ì²˜ë¦¬ ê°€ëŠ¥
    - ì œNì¥, ì œNì ˆ, ì œNì¡°, (ì¡°ë¬¸ëª…), â‘ â‘¡â‘¢ ë“± ì²˜ë¦¬
    """

    chunks = []

    # ì •ê·œì‹
    chapter_re = re.compile(r"(ì œ\d+ì¥\s*[^\s]*)")
    section_re = re.compile(r"(ì œ\d+ì ˆ\s*[^\s]*)")
    article_re = re.compile(r"(ì œ\d+ì¡°)\s*\((.*?)\)")
    clause_re = re.compile(r"([â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©])")

    # í˜„ì¬ ìƒíƒœ
    current_chapter = "-"
    current_section = "-"

    # í…ìŠ¤íŠ¸ ì „ì²´ì—ì„œ ëª¨ë‘ íƒìƒ‰
    chapters = list(chapter_re.finditer(text))
    sections = list(section_re.finditer(text))
    articles = list(article_re.finditer(text))

    # chapter & section ìœ„ì¹˜ ì¸ë±ì‹±
    chapter_positions = {m.start(): m.group(1) for m in chapters}
    section_positions = {m.start(): m.group(1) for m in sections}

    # ê° ì¡°ë¬¸(article) ìˆœíšŒ
    for idx, art in enumerate(articles):
        article = art.group(1)
        title = art.group(2).strip()
        start = art.end()

        # ë‹¤ìŒ ì¡°ë¬¸ ì‹œì‘ ì§€ì 
        end = articles[idx+1].start() if idx + 1 < len(articles) else len(text)

        body = text[start:end].strip()

        # í˜„ì¬ ì¡°ë¬¸ ì•ì— chapter/sectionì´ ìˆëŠ”ì§€ í™•ì¸
        for pos in sorted(chapter_positions.keys()):
            if pos < art.start():
                current_chapter = chapter_positions[pos]
            else:
                break

        for pos in sorted(section_positions.keys()):
            if pos < art.start():
                current_section = section_positions[pos]
            else:
                break

        # í•­ ë¶„ë¦¬
        clauses = clause_re.split(body)

        # í•­ì´ ì—†ëŠ” ì¡°ë¬¸
        if len(clauses) <= 1:
            chunks.append({
                "strategy": "law",
                "chapter": current_chapter,
                "section": current_section,
                "article": article,
                "title": title,
                "clause": "-",
                "text": body
            })
            continue

        # í•­ì´ ìˆëŠ” ì¡°ë¬¸
        for i in range(1, len(clauses), 2):
            clause_no = clauses[i]        # â‘ 
            clause_text = clauses[i+1].strip()  # ë‚´ìš©

            chunks.append({
                "strategy": "law",
                "chapter": current_chapter,
                "section": current_section,
                "article": article,
                "title": title,
                "clause": clause_no,
                "text": clause_text
            })

    return chunks

# ===== REGULAR CHUNK =====
def chunk_regular(text: str, cfg) -> List[Dict]:
    chunk_size = cfg.get("chunk_size", 800)
    overlap = cfg.get("overlap", 80)
    blocks = []
    start = 0
    while start < len(text):
        end = min(start + chunk_size, len(text))
        blocks.append({"text": text[start:end]})
        start += max(chunk_size - overlap, 1)
    return blocks

#  =====  COLUMN RECORD (CSV) =====
def chunk_column_record(text: str, cfg) -> List[Dict]:
    mapping = cfg.get("mapping", {})
    rows = [line.split(",") for line in text.splitlines() if line.strip()]

    out = []
    for row in rows:
        obj = {k: (row[idx] if idx < len(row) else None)
               for k, idx in mapping.items()}
        obj["strategy"] = "csv"
        obj["page_no"] = "-"
        out.append(obj)
    return out

# ===== PAGE STRATEGY (onnurigift) =====
def chunk_page(text: str) -> List[Dict]:
    return [{"strategy": "page", "text": text}]

# ===== APPLY STRATEGY =====
def get_chunk_strategy(file_name: str):
    cfg = load_config()
    ext = "pdf" if file_name.lower().endswith(".pdf") else "csv"
    return cfg.get(ext, {}).get(file_name, cfg.get("default", {}))


def apply_chunk_strategy(raw_text: str, file_name: str) -> List[Dict]:
    cfg = get_chunk_strategy(file_name)
    strategy = cfg.get("strategy", "regular")

    if strategy == "law":
        return parse_law_pdf_text(raw_text)

    elif strategy == "category":
        return parse_category_structure(raw_text)

    elif strategy == "column_record":
        return chunk_column_record(raw_text, cfg)

    elif strategy == "page":
        return chunk_page(raw_text)

    else:
        return chunk_regular(raw_text, cfg)

def chunk_text_dynamic(text: str, file_name: str) -> List[Dict]:
    return apply_chunk_strategy(text, file_name)

chunk_text = chunk_text_dynamic
